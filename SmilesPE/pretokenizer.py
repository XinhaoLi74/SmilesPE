# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks_build/00_pretokenizer.ipynb (unless otherwise specified).

__all__ = ['atomwise_tokenizer', 'kmer_tokenizer', 'tokens_to_mer']

# Cell
def atomwise_tokenizer(smiles, exclusive_tokens = None):
    """
    Tokenize a SMILES molecule at atom-level:
        (1) 'Br' and 'Cl' are two-character tokens
        (2) Symbols with bracket are considered as tokens
        (3) All other symbols are tokenized on character level.

    exclusive_tokens: A list of specifical symbols with bracket you want to keep. e.g., ['[C@@H]', '[nH]'].
    Other symbols with bracket will be replaced by '[UNK]'. default is `None`.
    """
    import re
    from functools import reduce
    regex = '(\[[^\[\]]{1,10}\])'
    char_list = re.split(regex, smiles)
    tokens = []

    if exclusive_tokens:
        for char in char_list:
            if char.startswith('['):
                if char in exclusive_tokens:
                    tokens.append(str(char))
                else:
                    tokens.append('[UNK]')
            else:
                chars = [unit for unit in char]
                [tokens.append(i) for i in chars]

    if not exclusive_tokens:
        for char in char_list:
            if char.startswith('['):
                tokens.append(str(char))
            else:
                chars = [unit for unit in char]
                [tokens.append(i) for i in chars]

    #fix the 'Br' be splited into 'B' and 'r'
    if 'r' in tokens:
        for index, tok in enumerate(tokens):
            if tok == 'r':
                if tokens[index-1] == 'B':
                        tokens[index-1: index+1] = [reduce(lambda i, j: i + j, tokens[index-1 : index+1])]

    #fix the 'Cl' be splited into 'C' and 'l'
    if 'l' in tokens:
        for index, tok in enumerate(tokens):
            if tok == 'l':
                if tokens[index-1] == 'C':
                        tokens[index-1: index+1] = [reduce(lambda i, j: i + j, tokens[index-1 : index+1])]
    return tokens

# Cell

def kmer_tokenizer(smiles, ngram=4, stride=1, remove_last = False, exclusive_tokens = None):
    units = atomwise_tokenizer(smiles, exclusive_tokens = exclusive_tokens) #collect all the atom-wise tokens from the SMILES
    if ngram == 1:
        tokens = units
    else:
        tokens = [tokens_to_mer(units[i:i+ngram]) for i in range(0, len(units), stride) if len(units[i:i+ngram]) == ngram]

    if remove_last:
        if len(tokens[-1]) < ngram: #truncate last whole k-mer if the length of the last k-mers is less than ngram.
            tokens = tokens[:-1]
    return tokens

def tokens_to_mer(toks):
    return ''.join(toks)